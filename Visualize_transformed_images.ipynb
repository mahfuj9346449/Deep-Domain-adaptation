{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table_of_content\n",
    "\n",
    "- [Visualize domain adapted images](#Visualize_domain_adapted_images)\n",
    "- [Simple npy file](#Simple_npy_file_visualization)\n",
    "- [Color arithmetic](#Test_color_arithmetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from time import time\n",
    "\n",
    "ROOT_path = os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize three datasets (MNIST, domain adaptated, MNIST-M)\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_domain_imgs_path = os.path.join(ROOT_path, '.keras/datasets/mnist_x.npy')\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/generated.npy\"\n",
    "domain_adapted_imgs_path = \"./domain_adapted/Exp7/generated.npy\"\n",
    "target_domain_imgs_path = os.path.join(ROOT_path, '.keras/datasets/mnistm_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "print(\"Loading data...\")\n",
    "st = time()\n",
    "source_domain_images = np.load(source_domain_imgs_path)\n",
    "domain_adapted_images = np.load(domain_adapted_imgs_path)\n",
    "target_domain_images = np.load(target_domain_imgs_path)\n",
    "\n",
    "# The above images have pixel values in [-1,1]\n",
    "source_domain_images = (source_domain_images+1)/2.\n",
    "domain_adapted_images = (domain_adapted_images+1)/2.\n",
    "target_domain_images = (target_domain_images+1)/2.\n",
    "et = time()\n",
    "print(\"Done.\")\n",
    "print(\"Elapsed time {}\".format(et-st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['viridis'] + sorted(m for m in plt.cm.datad if not m.endswith(\"_r\"))\n",
    "def show_result_from_npy_improved(i, colormap1='gray', colormap2='Reds', colormap3='Blues', **kwargs):\n",
    "    \"\"\"\n",
    "    Take tensor .npy as input\n",
    "    \"\"\"\n",
    "    global source_domain_images\n",
    "    global domain_adapted_images\n",
    "    global target_domain_images\n",
    "#     img_body = np.squeeze(bodys[i])#*255\n",
    "#     img_liver_predict = np.squeeze(liver_predict[i])#*255\n",
    "#     img_liver_gt = np.squeeze(liver_gt[i])#*255\n",
    "    \n",
    "#     print(np.sum(img_liver_predict))\n",
    "    f, axes = plt.subplots(1,3, figsize=(15, 45))\n",
    "    axes[0].set_title(\"Source domain images\")\n",
    "    axes[0].imshow(source_domain_images[i])#, cmap=colormap1\n",
    "#     if mask:\n",
    "#         axes[0].imshow(img_liver_gt, aspect=\"equal\", cmap=colormap3, alpha=0.4)\n",
    "#     if mask_with_predict:\n",
    "#         axes[0].imshow(img_liver_predict, aspect=\"equal\", cmap=colormap2, alpha=0.3)\n",
    "    \n",
    "#     axes[0,1].set_title(\"Liver mask prediction\")\n",
    "#     axes[0,1].imshow(img_liver_predict, aspect=\"equal\", cmap=colormap2)\n",
    "#     axes[1,0].set_title(\"Liver mask ground truth\")\n",
    "#     axes[1,0].imshow(img_liver_gt, aspect=\"equal\", cmap=colormap3)\n",
    "    axes[1].set_title(\"Domain adapted images\")#.format(dice_all[i]))\n",
    "    axes[1].imshow(domain_adapted_images[i])\n",
    "#     if show_gt:\n",
    "#         axes[1].imshow(img_liver_gt, aspect=\"equal\", cmap=colormap3, alpha=0.5)\n",
    "#     if show_predict:\n",
    "#         axes[1].imshow(img_liver_predict, aspect=\"equal\", cmap=colormap2, alpha=0.5)\n",
    "    axes[2].set_title(\"Target domain images\")#.format(dice_all[i]))\n",
    "    axes[2].imshow(target_domain_images[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(show_result_from_npy_improved, i=(0,len(domain_adapted_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize_domain_adapted_images\n",
    "\n",
    "- [Home](#Table_of_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_domain_imgs_path = os.path.join(ROOT_path, '.keras/datasets/mnist_x.npy')\n",
    "global domain_adapted_imgs_path\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/Exp0_gaussian_noise_1024_no_batchnorm/debug1.npy\"\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/Paper2_exp2/debug.npy\"\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/WGAN_GP/Exp3/debug.npy\"\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/WGAN_GP/Exp4/debug_sobol.npy\"\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/WGAN_GP/Exp4/debug_sphere.npy\"\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/WGAN_GP/Exp4/debug_uniform_linear.npy\"\n",
    "\n",
    "domain_adapted_imgs_path = \"./domain_adapted/WGAN_GP/Exp4_12/debug_uniform_linear.npy\"\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/WGAN_GP/Exp4_12/debug_linear.npy\"\n",
    "## One of the best:\n",
    "# domain_adapted_imgs_path = \"./domain_adapted/WGAN_GP/Exp4/debug_linear.npy\"\n",
    "\n",
    "target_domain_imgs_path = os.path.join(ROOT_path, '.keras/datasets/mnistm_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "1.0 -1.0\n",
      "1.0 -0.9999998\n",
      "1.0 -1.0\n",
      "Done.\n",
      "Elapsed time 7.089370250701904\n",
      "(100, 256, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "global domain_adapted_images\n",
    "print(\"Loading data...\")\n",
    "st = time()\n",
    "source_domain_images = np.load(source_domain_imgs_path)\n",
    "domain_adapted_images = np.load(domain_adapted_imgs_path)\n",
    "target_domain_images = np.load(target_domain_imgs_path)\n",
    "\n",
    "print(np.max(source_domain_images), np.min(source_domain_images))\n",
    "print(np.max(domain_adapted_images), np.min(domain_adapted_images))\n",
    "print(np.max(target_domain_images), np.min(target_domain_images))\n",
    "# The above images have pixel values in [-1,1]\n",
    "source_domain_images = (source_domain_images+1)/2.\n",
    "domain_adapted_images = (domain_adapted_images+1)/2.\n",
    "target_domain_images = (target_domain_images+1)/2.\n",
    "et = time()\n",
    "print(\"Done.\")\n",
    "print(\"Elapsed time {}\".format(et-st))\n",
    "print(domain_adapted_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['viridis'] + sorted(m for m in plt.cm.datad if not m.endswith(\"_r\"))\n",
    "# def show_result_from_npy_improved(i, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Take tensor .npy as input\n",
    "#     \"\"\"\n",
    "#     global source_domain_images\n",
    "#     global domain_adapted_images\n",
    "#     global target_domain_images\n",
    "#     r = 3\n",
    "#     c = 15\n",
    "#     fig, axs = plt.subplots(r, c, figsize=(15*int(c/r), 15))\n",
    "    \n",
    "#     for j in range(c):\n",
    "#         axs[0,j].imshow(source_domain_images[j])\n",
    "#         #axs[i, j].set_title(titles[i])\n",
    "#         axs[0,j].axis('off')\n",
    "#     for j in range(c):\n",
    "#         axs[1,j].imshow(domain_adapted_images[i][j])\n",
    "#         #axs[i, j].set_title(titles[i])\n",
    "#         axs[1,j].axis('off')\n",
    "#     print(len(domain_adapted_images[i]))\n",
    "    \n",
    "#     for j in range(c):\n",
    "#         axs[2,j].imshow(target_domain_images[j])\n",
    "#         #axs[i, j].set_title(titles[i])\n",
    "#         axs[2,j].axis('off')\n",
    "def show_generated_imgs(r=5, c=15, batch=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Take tensor .npy as input\n",
    "    \"\"\"\n",
    "    global source_domain_images\n",
    "    global domain_adapted_images\n",
    "    global target_domain_images\n",
    "\n",
    "#     r = 3\n",
    "#     c = 15\n",
    "    print(np.random.random(10))\n",
    "    fig, axs = plt.subplots(r, c, figsize=(5*c, 5*r))\n",
    "    for j in range(r):\n",
    "        for i in range(c):\n",
    "            axs[j,i].imshow(domain_adapted_images[j+batch*r][i+batch*c])\n",
    "            #axs[i, j].set_title(titles[i])\n",
    "            axs[j,i].axis('off')\n",
    "\n",
    "def advanced_show(r=5, c=15, batch=0, filepath=domain_adapted_imgs_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Take tensor .npy as input\n",
    "    \"\"\"\n",
    "    global domain_adapted_imgs_path\n",
    "    global domain_adapted_images\n",
    "    if filepath == domain_adapted_imgs_path:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Previous filepath: {}\".format(domain_adapted_imgs_path))\n",
    "        print(\"Current filepath: {}\".format(filepath))\n",
    "        domain_adapted_imgs_path = filepath\n",
    "        print(\"Loading data...\")\n",
    "        st = time()\n",
    "        domain_adapted_images = np.load(domain_adapted_imgs_path)\n",
    "        print(np.max(domain_adapted_images), np.min(domain_adapted_images))\n",
    "        # The above images have pixel values in [-1,1]\n",
    "        domain_adapted_images = (domain_adapted_images+1)/2.\n",
    "        et = time()\n",
    "        print(\"Done.\")\n",
    "        print(\"Elapsed time {}\".format(et-st))\n",
    "        \n",
    "\n",
    "    fig, axs = plt.subplots(r, c, figsize=(5*c, 5*r))\n",
    "    for j in range(r):\n",
    "        for i in range(c):\n",
    "            axs[j,i].imshow(domain_adapted_images[j+batch*r][i+batch*c])\n",
    "            #axs[i, j].set_title(titles[i])\n",
    "            axs[j,i].axis('off') \n",
    "def advanced_show_rainbow(r=5, c=15, batch_imgs=0, batch_noise=0, filepath=domain_adapted_imgs_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Take tensor .npy as input\n",
    "    \"\"\"\n",
    "    global domain_adapted_imgs_path\n",
    "    global domain_adapted_images\n",
    "    if filepath == domain_adapted_imgs_path:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Previous filepath: {}\".format(domain_adapted_imgs_path))\n",
    "        print(\"Current filepath: {}\".format(filepath))\n",
    "        domain_adapted_imgs_path = filepath\n",
    "        print(\"Loading data...\")\n",
    "        st = time()\n",
    "        domain_adapted_images = np.load(domain_adapted_imgs_path)\n",
    "        print(np.max(domain_adapted_images), np.min(domain_adapted_images))\n",
    "        # The above images have pixel values in [-1,1]\n",
    "        domain_adapted_images = (domain_adapted_images+1)/2.\n",
    "        et = time()\n",
    "        print(\"Done.\")\n",
    "        print(\"Elapsed time {}\".format(et-st))\n",
    "        \n",
    "\n",
    "    fig, axs = plt.subplots(r, c, figsize=(5*c, 5*r))\n",
    "    for j in range(r):\n",
    "        for i in range(c):\n",
    "            axs[j,i].imshow(domain_adapted_images[j+batch_imgs*r][i+batch_noise*c])\n",
    "            #axs[i, j].set_title(titles[i])\n",
    "            axs[j,i].axis('off') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67270c4527e4e5c8c47d3d5d8afed96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='r', max=15, min=-5), IntSlider(value=15, description='c', max=45, min=-15), IntSlider(value=0, description='batch', max=17), Text(value='./domain_adapted/WGAN_GP/Exp4_12/debug_uniform_linear.npy', description='filepath'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.advanced_show(r=5, c=15, batch=0, filepath='./domain_adapted/WGAN_GP/Exp4_12/debug_uniform_linear.npy', **kwargs)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interact(show_generated_imgs, batch=(0,17))\n",
    "interact(advanced_show, batch=(0,17))\n",
    "\n",
    "# linear\n",
    "# uniform_linear\n",
    "# sphere\n",
    "# zeros\n",
    "# _11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e5c7691e2c4dc985466366a01b6a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='r', max=15, min=-5), IntSlider(value=15, description='c', max=45, min=-15), IntSlider(value=0, description='batch_imgs', max=20), IntSlider(value=0, description='batch_noise', max=17), Text(value='./domain_adapted/WGAN_GP/Exp4_12/debug_uniform_linear.npy', description='filepath'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.advanced_show_rainbow(r=5, c=15, batch_imgs=0, batch_noise=0, filepath='./domain_adapted/WGAN_GP/Exp4_12/debug_uniform_linear.npy', **kwargs)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = domain_adapted_images.shape[0]\n",
    "num_noises = domain_adapted_images.shape[1]\n",
    "interact(advanced_show_rainbow, batch_imgs=(0,int(num_samples/5)), batch_noise=(0, int(num_noises/15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interact(show_result_from_npy_improved, i=(0,len(domain_adapted_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack jupyter widget ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global FILENAME\n",
    "FILENAME = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_interact(filename=FILENAME):\n",
    "    global FILENAME\n",
    "    print(filename == FILENAME)\n",
    "    print(FILENAME)\n",
    "    print(filename)\n",
    "    a = filename == FILENAME\n",
    "    print(a)\n",
    "    if filename == FILENAME:\n",
    "        print(True)\n",
    "        pass\n",
    "    else:\n",
    "        print(False)\n",
    "        \n",
    "        s = FILENAME\n",
    "        print(s)\n",
    "        FILENAME = filename\n",
    "#     if filename == FILENAME:\n",
    "#         print(filename == FILENAME)\n",
    "#         pass\n",
    "#     else:\n",
    "#         FILENAME = filename\n",
    "#         print(\"New filename {}\".format(filename))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(test_interact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple_npy_file_visualization\n",
    "\n",
    "- [Home](#Table_of_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLDER_name = \"./output/output10_x_batchnorm/train\"\n",
    "filepath = os.path.join(ROOT_path, '.keras/datasets/mnistm_x.npy')\n",
    "with_mask = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['viridis'] + sorted(m for m in plt.cm.datad if not m.endswith(\"_r\"))\n",
    "print(\"Loading data...\")\n",
    "st = time()\n",
    "bodys = np.load(filepath)\n",
    "bodys = (bodys+1)/2.0\n",
    "if with_mask:\n",
    "    liver_gt = np.load(\"{}/liver_masks.npy\".format(FOLDER_name))\n",
    "    \n",
    "et = time()\n",
    "print(\"Done.\")\n",
    "print(\"Elapsed time {}\".format(et-st))\n",
    "\n",
    "def show_images_from_npy_simple(i, mask=False, colormap1='gray', **kwargs):\n",
    "    \"\"\"\n",
    "    Take tensor .npy as input\n",
    "    \"\"\"\n",
    "    global bodys\n",
    "    if with_mask:\n",
    "        global liver_gt\n",
    "    img_body = np.squeeze(bodys[i])#*255\n",
    "    if with_mask:\n",
    "        img_liver_gt = np.squeeze(liver_gt[i])#*255\n",
    "    \n",
    "    if with_mask:\n",
    "        f, axes = plt.subplots(1,2, figsize=(10, 20))\n",
    "        axes[0].set_title(\"Axial\")\n",
    "        axes[0].imshow(img_body, cmap=colormap1)\n",
    "        if mask:\n",
    "            axes[0].imshow(img_liver_gt, aspect=\"equal\", cmap=\"Blues\", alpha=0.4)\n",
    "\n",
    "\n",
    "        axes[1].set_title(\"Liver mask ground truth\")\n",
    "        axes[1].imshow(img_liver_gt, aspect=\"equal\", cmap=\"Blues\")\n",
    "    else:\n",
    "        f, axes = plt.subplots(1,1, figsize=(5, 5))\n",
    "        axes.set_title(\"Axial\")\n",
    "        axes.imshow(img_body, cmap=colormap1)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(show_images_from_npy_simple, i=(0,len(bodys)), mask=False, colormap1=COLORS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test_color_arithmetic\n",
    "\n",
    "- [Home](#Table_of_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = np.zeros((32,32,3))\n",
    "red[:,:,0] = 1\n",
    "green = np.zeros((32,32,3))\n",
    "green[:,:,1] = 1\n",
    "blue = np.zeros((32,32,3))\n",
    "blue[:,:,2] = 1\n",
    "yellow = red+green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,3, figsize=(30, 10))\n",
    "axes[0].imshow(red)\n",
    "axes[1].imshow(green)\n",
    "axes[2].imshow(blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,3, figsize=(30, 10))\n",
    "axes[0].imshow(red)\n",
    "axes[1].imshow(green)\n",
    "axes[2].imshow(red+green)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
